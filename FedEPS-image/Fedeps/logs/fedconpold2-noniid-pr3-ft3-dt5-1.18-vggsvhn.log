Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.5874)
Warm up stage:accuracy: tensor(19.6335)
Warm up stage:accuracy: tensor(30.8620)
Warm up stage:accuracy: tensor(32.6099)
Warm up stage:accuracy: tensor(37.7996)
Warm up stage:accuracy: tensor(38.6486)
Warm up stage:accuracy: tensor(41.2800)
Warm up stage:accuracy: tensor(45.1521)
Warm up stage:accuracy: tensor(55.5816)
Warm up stage:accuracy: tensor(59.0350)
Warm up stage:accuracy: tensor(59.5498)
Warm up stage:accuracy: tensor(66.7333)
Warm up stage:accuracy: tensor(71.4620)
Warm up stage:accuracy: tensor(75.5416)
Warm up stage:accuracy: tensor(75.5416)
Warm up stage:accuracy: tensor(75.6415)
Warm up stage:accuracy: tensor(81.2039)
Warm up stage:accuracy: tensor(84.2386)
Warm up stage:accuracy: tensor(84.2386)
Warm up stage:accuracy: tensor(84.2386)
Warm up stage:accuracy: tensor(84.3039)
Warm up stage:accuracy: tensor(84.9493)
Warm up stage:accuracy: tensor(85.4487)
Warm up stage:accuracy: tensor(89.1249)
Warm up stage:accuracy: tensor(89.1249)
Warm up stage:accuracy: tensor(89.1249)
total_num_list [200352380, 147665837]
===============================================
round: 0
Participants: [91 70 20 47 41 79 19 21 61 18]
Accuracy before training:
[tensor(75.8621), tensor(84.6154), tensor(78.0702), tensor(74.1071), tensor(84.4828), tensor(75.), tensor(80.1724), tensor(77.9661), tensor(69.5652), tensor(88.6957)]
Accuracy After finetune:
[tensor(90.5172), tensor(88.8889), tensor(89.4737), tensor(98.2143), tensor(91.3793), tensor(97.3214), tensor(84.4828), tensor(86.4407), tensor(83.4783), tensor(93.0435)]
Accuracy After distillation:
[tensor(84.4828), tensor(83.7607), tensor(89.4737), tensor(79.4643), tensor(87.9310), tensor(90.1786), tensor(85.3448), tensor(85.5932), tensor(80.8696), tensor(90.4348)]
=============================================
accuracy [array(86.08696, dtype=float32), array(86.08696, dtype=float32), array(77.192986, dtype=float32), array(89.47369, dtype=float32), array(85.344826, dtype=float32), array(86.206894, dtype=float32), array(86.95652, dtype=float32), array(75.21368, dtype=float32), array(84.347824, dtype=float32), array(59.482758, dtype=float32), array(91.22807, dtype=float32), array(86.206894, dtype=float32), array(85.344826, dtype=float32), array(88.793106, dtype=float32), array(88.793106, dtype=float32), array(87.06896, dtype=float32), array(83.62069, dtype=float32), array(88.28829, dtype=float32), array(90.434784, dtype=float32), array(85.344826, dtype=float32), array(89.47369, dtype=float32), array(85.59322, dtype=float32), array(81.034485, dtype=float32), array(80., dtype=float32), array(85.96491, dtype=float32), array(69.565216, dtype=float32), array(81.89655, dtype=float32), array(61.739132, dtype=float32), array(73.27586, dtype=float32), array(74.5614, dtype=float32), array(65.811966, dtype=float32), array(74.78261, dtype=float32), array(86.60714, dtype=float32), array(70.68965, dtype=float32), array(85.58559, dtype=float32), array(78.947365, dtype=float32), array(78.63248, dtype=float32), array(87.7193, dtype=float32), array(58.974358, dtype=float32), array(84.210526, dtype=float32), array(59.130436, dtype=float32), array(87.93104, dtype=float32), array(74.78261, dtype=float32), array(81.355934, dtype=float32), array(85.21739, dtype=float32), array(82.45614, dtype=float32), array(82.75862, dtype=float32), array(79.46429, dtype=float32), array(78.070175, dtype=float32), array(81.73913, dtype=float32), array(67.82609, dtype=float32), array(81.89655, dtype=float32), array(83.76068, dtype=float32), array(77.192986, dtype=float32), array(82.051285, dtype=float32), array(66.08696, dtype=float32), array(94.5946, dtype=float32), array(80.18018, dtype=float32), array(73.21429, dtype=float32), array(77.192986, dtype=float32), array(90.09009, dtype=float32), array(80.86957, dtype=float32), array(53.448277, dtype=float32), array(86.95652, dtype=float32), array(80.17242, dtype=float32), array(52.173912, dtype=float32), array(87.06896, dtype=float32), array(79.82456, dtype=float32), array(87.17949, dtype=float32), array(89.47369, dtype=float32), array(83.76068, dtype=float32), array(85.344826, dtype=float32), array(85.96491, dtype=float32), array(82.608696, dtype=float32), array(88.695656, dtype=float32), array(88.695656, dtype=float32), array(78.070175, dtype=float32), array(71.55173, dtype=float32), array(80.86957, dtype=float32), array(90.17857, dtype=float32), array(81.034485, dtype=float32), array(82.608696, dtype=float32), array(83.333336, dtype=float32), array(83.333336, dtype=float32), array(84.210526, dtype=float32), array(82.75862, dtype=float32), array(74.5614, dtype=float32), array(81.57895, dtype=float32), array(54.385963, dtype=float32), array(85.344826, dtype=float32), array(84.210526, dtype=float32), array(84.48276, dtype=float32), array(64.347824, dtype=float32), array(87.38739, dtype=float32), array(80.70175, dtype=float32), array(64.95727, dtype=float32), array(86.95652, dtype=float32), array(79.31035, dtype=float32), array(83.478264, dtype=float32), array(80., dtype=float32)]
average accuracy 80.35465198516846
average accuracy list [80.35465198516846]
-------------------------------------------
total_num_list [200352380, 147665837, 142073363]
===============================================
round: 1
Participants: [79 93 72 63  1 58 34 80 38 29]
Accuracy before training:
[tensor(90.1786), tensor(86.4865), tensor(85.9649), tensor(92.1739), tensor(86.0870), tensor(74.1071), tensor(83.7838), tensor(79.3103), tensor(61.5385), tensor(78.0702)]
Accuracy After finetune:
[tensor(92.8571), tensor(89.1892), tensor(88.5965), tensor(93.0435), tensor(85.2174), tensor(91.0714), tensor(95.4955), tensor(88.7931), tensor(73.5043), tensor(90.3509)]
Accuracy After distillation:
[tensor(89.2857), tensor(86.4865), tensor(82.4561), tensor(82.6087), tensor(84.3478), tensor(84.8214), tensor(85.5856), tensor(86.2069), tensor(82.0513), tensor(89.4737)]
=============================================
accuracy [array(86.08696, dtype=float32), array(84.347824, dtype=float32), array(77.192986, dtype=float32), array(89.47369, dtype=float32), array(85.344826, dtype=float32), array(86.206894, dtype=float32), array(86.95652, dtype=float32), array(75.21368, dtype=float32), array(84.347824, dtype=float32), array(59.482758, dtype=float32), array(91.22807, dtype=float32), array(86.206894, dtype=float32), array(85.344826, dtype=float32), array(88.793106, dtype=float32), array(88.793106, dtype=float32), array(87.06896, dtype=float32), array(83.62069, dtype=float32), array(88.28829, dtype=float32), array(90.434784, dtype=float32), array(85.344826, dtype=float32), array(89.47369, dtype=float32), array(85.59322, dtype=float32), array(81.034485, dtype=float32), array(80., dtype=float32), array(85.96491, dtype=float32), array(69.565216, dtype=float32), array(81.89655, dtype=float32), array(61.739132, dtype=float32), array(73.27586, dtype=float32), array(89.47369, dtype=float32), array(65.811966, dtype=float32), array(74.78261, dtype=float32), array(86.60714, dtype=float32), array(70.68965, dtype=float32), array(85.58559, dtype=float32), array(78.947365, dtype=float32), array(78.63248, dtype=float32), array(87.7193, dtype=float32), array(82.051285, dtype=float32), array(84.210526, dtype=float32), array(59.130436, dtype=float32), array(87.93104, dtype=float32), array(74.78261, dtype=float32), array(81.355934, dtype=float32), array(85.21739, dtype=float32), array(82.45614, dtype=float32), array(82.75862, dtype=float32), array(79.46429, dtype=float32), array(78.070175, dtype=float32), array(81.73913, dtype=float32), array(67.82609, dtype=float32), array(81.89655, dtype=float32), array(83.76068, dtype=float32), array(77.192986, dtype=float32), array(82.051285, dtype=float32), array(66.08696, dtype=float32), array(94.5946, dtype=float32), array(80.18018, dtype=float32), array(84.82143, dtype=float32), array(77.192986, dtype=float32), array(90.09009, dtype=float32), array(80.86957, dtype=float32), array(53.448277, dtype=float32), array(82.608696, dtype=float32), array(80.17242, dtype=float32), array(52.173912, dtype=float32), array(87.06896, dtype=float32), array(79.82456, dtype=float32), array(87.17949, dtype=float32), array(89.47369, dtype=float32), array(83.76068, dtype=float32), array(85.344826, dtype=float32), array(82.45614, dtype=float32), array(82.608696, dtype=float32), array(88.695656, dtype=float32), array(88.695656, dtype=float32), array(78.070175, dtype=float32), array(71.55173, dtype=float32), array(80.86957, dtype=float32), array(89.28571, dtype=float32), array(86.206894, dtype=float32), array(82.608696, dtype=float32), array(83.333336, dtype=float32), array(83.333336, dtype=float32), array(84.210526, dtype=float32), array(82.75862, dtype=float32), array(74.5614, dtype=float32), array(81.57895, dtype=float32), array(54.385963, dtype=float32), array(85.344826, dtype=float32), array(84.210526, dtype=float32), array(84.48276, dtype=float32), array(64.347824, dtype=float32), array(86.48649, dtype=float32), array(80.70175, dtype=float32), array(64.95727, dtype=float32), array(86.95652, dtype=float32), array(79.31035, dtype=float32), array(83.478264, dtype=float32), array(80., dtype=float32)]
average accuracy 80.78844463348389
average accuracy list [80.35465198516846, 80.78844463348389]
-------------------------------------------
total_num_list [200352380, 147665837, 142073363, 136406809]
===============================================
round: 2
Participants: [62 42 19 82 16 20  4 40 44  6]
Accuracy before training:
[tensor(52.5862), tensor(76.5217), tensor(87.0690), tensor(83.3333), tensor(81.8966), tensor(90.3509), tensor(86.2069), tensor(58.2609), tensor(83.4783), tensor(84.3478)]
Accuracy After finetune:
[tensor(65.5172), tensor(92.1739), tensor(88.7931), tensor(83.3333), tensor(90.5172), tensor(93.8596), tensor(92.2414), tensor(63.4783), tensor(92.1739), tensor(91.3043)]
Accuracy After distillation:
[tensor(78.4483), tensor(80.8696), tensor(87.9310), tensor(84.2105), tensor(85.3448), tensor(90.3509), tensor(86.2069), tensor(82.6087), tensor(88.6957), tensor(81.7391)]
=============================================
accuracy [array(86.08696, dtype=float32), array(84.347824, dtype=float32), array(77.192986, dtype=float32), array(89.47369, dtype=float32), array(86.206894, dtype=float32), array(86.206894, dtype=float32), array(81.73913, dtype=float32), array(75.21368, dtype=float32), array(84.347824, dtype=float32), array(59.482758, dtype=float32), array(91.22807, dtype=float32), array(86.206894, dtype=float32), array(85.344826, dtype=float32), array(88.793106, dtype=float32), array(88.793106, dtype=float32), array(87.06896, dtype=float32), array(85.344826, dtype=float32), array(88.28829, dtype=float32), array(90.434784, dtype=float32), array(87.93104, dtype=float32), array(90.350876, dtype=float32), array(85.59322, dtype=float32), array(81.034485, dtype=float32), array(80., dtype=float32), array(85.96491, dtype=float32), array(69.565216, dtype=float32), array(81.89655, dtype=float32), array(61.739132, dtype=float32), array(73.27586, dtype=float32), array(89.47369, dtype=float32), array(65.811966, dtype=float32), array(74.78261, dtype=float32), array(86.60714, dtype=float32), array(70.68965, dtype=float32), array(85.58559, dtype=float32), array(78.947365, dtype=float32), array(78.63248, dtype=float32), array(87.7193, dtype=float32), array(82.051285, dtype=float32), array(84.210526, dtype=float32), array(82.608696, dtype=float32), array(87.93104, dtype=float32), array(80.86957, dtype=float32), array(81.355934, dtype=float32), array(88.695656, dtype=float32), array(82.45614, dtype=float32), array(82.75862, dtype=float32), array(79.46429, dtype=float32), array(78.070175, dtype=float32), array(81.73913, dtype=float32), array(67.82609, dtype=float32), array(81.89655, dtype=float32), array(83.76068, dtype=float32), array(77.192986, dtype=float32), array(82.051285, dtype=float32), array(66.08696, dtype=float32), array(94.5946, dtype=float32), array(80.18018, dtype=float32), array(84.82143, dtype=float32), array(77.192986, dtype=float32), array(90.09009, dtype=float32), array(80.86957, dtype=float32), array(78.44827, dtype=float32), array(82.608696, dtype=float32), array(80.17242, dtype=float32), array(52.173912, dtype=float32), array(87.06896, dtype=float32), array(79.82456, dtype=float32), array(87.17949, dtype=float32), array(89.47369, dtype=float32), array(83.76068, dtype=float32), array(85.344826, dtype=float32), array(82.45614, dtype=float32), array(82.608696, dtype=float32), array(88.695656, dtype=float32), array(88.695656, dtype=float32), array(78.070175, dtype=float32), array(71.55173, dtype=float32), array(80.86957, dtype=float32), array(89.28571, dtype=float32), array(86.206894, dtype=float32), array(82.608696, dtype=float32), array(84.210526, dtype=float32), array(83.333336, dtype=float32), array(84.210526, dtype=float32), array(82.75862, dtype=float32), array(74.5614, dtype=float32), array(81.57895, dtype=float32), array(54.385963, dtype=float32), array(85.344826, dtype=float32), array(84.210526, dtype=float32), array(84.48276, dtype=float32), array(64.347824, dtype=float32), array(86.48649, dtype=float32), array(80.70175, dtype=float32), array(64.95727, dtype=float32), array(86.95652, dtype=float32), array(79.31035, dtype=float32), array(83.478264, dtype=float32), array(80., dtype=float32)]
average accuracy 81.38597347259521
average accuracy list [80.35465198516846, 80.78844463348389, 81.38597347259521]
-------------------------------------------
total_num_list [200352380, 147665837, 142073363, 136406809, 130723996]
