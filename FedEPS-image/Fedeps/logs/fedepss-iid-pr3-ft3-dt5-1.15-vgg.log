Warm up stage:accuracy: tensor(27.8100)
Warm up stage:accuracy: tensor(37.3400)
Warm up stage:accuracy: tensor(41.2000)
Warm up stage:accuracy: tensor(45.5200)
Warm up stage:accuracy: tensor(48.3100)
Warm up stage:accuracy: tensor(49.2500)
Warm up stage:accuracy: tensor(51.9600)
Warm up stage:accuracy: tensor(55.5200)
Warm up stage:accuracy: tensor(55.5200)
Warm up stage:accuracy: tensor(56.6000)
total_num_list [200350180, 139392454]
training iter: 0 of 400
In this round, 10 clients are trained---->>>>
[77, 23, 97, 64, 49, 46, 65, 31, 18, 10]
Before Training, their test accuracy:
[array(56.179775, dtype=float32), array(55.555557, dtype=float32), array(48.314606, dtype=float32), array(53.846153, dtype=float32), array(56.52174, dtype=float32), array(50.5618, dtype=float32), array(59.34066, dtype=float32), array(53.932583, dtype=float32), array(53.932583, dtype=float32), array(48.863636, dtype=float32)]
After Finetune, their test accuracy:
[tensor(39.3258), tensor(35.5556), tensor(28.0899), tensor(37.3626), tensor(34.7826), tensor(25.8427), tensor(30.7692), tensor(40.4494), tensor(40.4494), tensor(26.1364)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(58.8889), tensor(49.4382), tensor(68.1319), tensor(52.1739), tensor(50.5618), tensor(58.2418), tensor(43.8202), tensor(50.5618), tensor(42.0455)]
average accuracy 54.27223934173584
average loss 1.2457949038069813
average train accuracy: 56.127067718505856
average accuracy ct 56.46749862670899
average accuracy list [54.27223934173584]
averge_train_accuracy_list [56.127067718505856]
averge_ct_accuracy_list [56.46749862670899]
total_num_list [200350180, 139392454, 134740471]
training iter: 1 of 400
In this round, 10 clients are trained---->>>>
[58, 65, 80, 51, 7, 34, 62, 9, 27, 48]
Before Training, their test accuracy:
[array(57.30337, dtype=float32), array(58.241756, dtype=float32), array(48.88889, dtype=float32), array(52.22222, dtype=float32), array(62.5, dtype=float32), array(60.215054, dtype=float32), array(57.954544, dtype=float32), array(61.11111, dtype=float32), array(62.637363, dtype=float32), array(51.136364, dtype=float32)]
After Finetune, their test accuracy:
[tensor(33.7079), tensor(48.3517), tensor(36.6667), tensor(35.5556), tensor(46.5909), tensor(36.5591), tensor(38.6364), tensor(32.2222), tensor(40.6593), tensor(31.8182)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(59.3407), tensor(57.7778), tensor(55.5556), tensor(64.7727), tensor(60.2151), tensor(55.6818), tensor(61.1111), tensor(50.5494), tensor(48.8636)]
average accuracy 54.26184425354004
average loss 1.2461285135193871
average train accuracy: 56.26826232910156
average accuracy ct 56.481598777771
average accuracy list [54.27223934173584, 54.26184425354004]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771]
total_num_list [200350180, 139392454, 134740471, 129981491]
training iter: 2 of 400
In this round, 10 clients are trained---->>>>
[59, 81, 75, 88, 7, 17, 95, 30, 46, 40]
Before Training, their test accuracy:
[array(47.727272, dtype=float32), array(46.590908, dtype=float32), array(57.608696, dtype=float32), array(52.173912, dtype=float32), array(64.77273, dtype=float32), array(54.444443, dtype=float32), array(54.444443, dtype=float32), array(54.65116, dtype=float32), array(50.5618, dtype=float32), array(52.272728, dtype=float32)]
After Finetune, their test accuracy:
[tensor(29.5455), tensor(34.0909), tensor(32.6087), tensor(42.3913), tensor(44.3182), tensor(38.8889), tensor(42.2222), tensor(33.7209), tensor(39.3258), tensor(21.5909)]
After distillation, their test accuracy:
[tensor(53.4091), tensor(47.7273), tensor(64.1304), tensor(63.0435), tensor(67.0455), tensor(47.7778), tensor(55.5556), tensor(51.1628), tensor(56.1798), tensor(53.4091)]
average accuracy 54.503770637512204
average loss 1.245568461301145
average train accuracy: 56.20110355377197
average accuracy ct 56.562298965454104
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902]
training iter: 3 of 400
In this round, 10 clients are trained---->>>>
[14, 82, 19, 38, 62, 81, 57, 17, 36, 6]
Before Training, their test accuracy:
[array(61.53846, dtype=float32), array(52.80899, dtype=float32), array(61.11111, dtype=float32), array(50.57471, dtype=float32), array(55.68182, dtype=float32), array(47.727272, dtype=float32), array(54.945053, dtype=float32), array(47.77778, dtype=float32), array(50., dtype=float32), array(43.820225, dtype=float32)]
After Finetune, their test accuracy:
[tensor(36.2637), tensor(23.5955), tensor(46.6667), tensor(27.5862), tensor(40.9091), tensor(40.9091), tensor(32.9670), tensor(47.7778), tensor(41.1111), tensor(28.0899)]
After distillation, their test accuracy:
[tensor(61.5385), tensor(50.5618), tensor(60.), tensor(50.5747), tensor(56.8182), tensor(56.8182), tensor(53.8462), tensor(63.3333), tensor(54.4444), tensor(56.1798)]
average accuracy 54.88506675720215
average loss 1.2387334705739463
average train accuracy: 56.607848777771
average accuracy ct 56.905699005126955
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771]
training iter: 4 of 400
In this round, 10 clients are trained---->>>>
[47, 75, 51, 21, 8, 44, 98, 74, 6, 31]
Before Training, their test accuracy:
[array(61.11111, dtype=float32), array(64.13043, dtype=float32), array(55.555557, dtype=float32), array(53.333332, dtype=float32), array(51.685394, dtype=float32), array(47.19101, dtype=float32), array(55.555557, dtype=float32), array(61.53846, dtype=float32), array(56.179775, dtype=float32), array(43.820225, dtype=float32)]
After Finetune, their test accuracy:
[tensor(41.1111), tensor(45.6522), tensor(40.), tensor(46.6667), tensor(33.7079), tensor(31.4607), tensor(34.4444), tensor(37.3626), tensor(43.8202), tensor(42.6966)]
After distillation, their test accuracy:
[tensor(66.6667), tensor(56.5217), tensor(62.2222), tensor(64.4444), tensor(56.1798), tensor(50.5618), tensor(58.8889), tensor(62.6374), tensor(53.9326), tensor(61.7978)]
average accuracy 55.32259052276611
average loss 1.2268836892313457
average train accuracy: 57.034880790710446
average accuracy ct 57.33059909820557
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587]
training iter: 5 of 400
In this round, 10 clients are trained---->>>>
[12, 35, 24, 9, 32, 54, 21, 43, 40, 87]
Before Training, their test accuracy:
[array(50., dtype=float32), array(51.64835, dtype=float32), array(57.30337, dtype=float32), array(61.11111, dtype=float32), array(56.32184, dtype=float32), array(47.252747, dtype=float32), array(64.44444, dtype=float32), array(47.77778, dtype=float32), array(53.409092, dtype=float32), array(56.179775, dtype=float32)]
After Finetune, their test accuracy:
[tensor(23.8636), tensor(39.5604), tensor(31.4607), tensor(54.4444), tensor(44.8276), tensor(35.1648), tensor(48.8889), tensor(36.6667), tensor(43.1818), tensor(28.0899)]
After distillation, their test accuracy:
[tensor(46.5909), tensor(46.1538), tensor(53.9326), tensor(60.), tensor(60.9195), tensor(64.8352), tensor(64.4444), tensor(47.7778), tensor(54.5455), tensor(50.5618)]
average accuracy 55.365720672607424
average loss 1.241438727464474
average train accuracy: 57.09573257446289
average accuracy ct 57.39509925842285
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915]
training iter: 6 of 400
In this round, 10 clients are trained---->>>>
[29, 13, 92, 76, 33, 58, 20, 63, 78, 90]
Before Training, their test accuracy:
[array(53.409092, dtype=float32), array(59.34066, dtype=float32), array(55.68182, dtype=float32), array(55.555557, dtype=float32), array(57.30337, dtype=float32), array(57.30337, dtype=float32), array(57.30337, dtype=float32), array(63.736263, dtype=float32), array(53.846153, dtype=float32), array(63.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(35.2273), tensor(39.5604), tensor(36.3636), tensor(43.3333), tensor(31.4607), tensor(40.4494), tensor(49.4382), tensor(48.3517), tensor(37.3626), tensor(38.8889)]
After distillation, their test accuracy:
[tensor(52.2727), tensor(48.3517), tensor(55.6818), tensor(50.), tensor(42.6966), tensor(49.4382), tensor(46.0674), tensor(53.8462), tensor(47.2527), tensor(57.7778)]
average accuracy 54.63144199371338
average loss 1.2679586339004312
average train accuracy: 56.67109725952148
average accuracy ct 56.849299392700196
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967]
training iter: 7 of 400
In this round, 10 clients are trained---->>>>
[12, 76, 96, 73, 29, 43, 7, 22, 21, 56]
Before Training, their test accuracy:
[array(46.590908, dtype=float32), array(50., dtype=float32), array(57.30337, dtype=float32), array(47.31183, dtype=float32), array(52.272728, dtype=float32), array(47.77778, dtype=float32), array(67.045456, dtype=float32), array(47.12644, dtype=float32), array(64.44444, dtype=float32), array(55.05618, dtype=float32)]
After Finetune, their test accuracy:
[tensor(35.2273), tensor(48.8889), tensor(35.9551), tensor(41.9355), tensor(37.5000), tensor(52.2222), tensor(56.8182), tensor(31.0345), tensor(57.7778), tensor(35.9551)]
After distillation, their test accuracy:
[tensor(47.7273), tensor(55.5556), tensor(64.0449), tensor(62.3656), tensor(61.3636), tensor(56.6667), tensor(61.3636), tensor(54.0230), tensor(54.4444), tensor(58.4270)]
average accuracy 55.04196773529053
average loss 1.2596465619172803
average train accuracy: 56.90446979522705
average accuracy ct 57.07509952545166
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313]
training iter: 8 of 400
In this round, 10 clients are trained---->>>>
[43, 21, 62, 93, 48, 77, 49, 4, 29, 25]
Before Training, their test accuracy:
[array(56.666668, dtype=float32), array(54.444443, dtype=float32), array(56.81818, dtype=float32), array(52.272728, dtype=float32), array(48.863636, dtype=float32), array(57.30337, dtype=float32), array(52.173912, dtype=float32), array(51.64835, dtype=float32), array(61.363636, dtype=float32), array(50., dtype=float32)]
After Finetune, their test accuracy:
[tensor(42.2222), tensor(56.6667), tensor(43.1818), tensor(43.1818), tensor(42.0455), tensor(41.5730), tensor(40.2174), tensor(28.5714), tensor(48.8636), tensor(26.1364)]
After distillation, their test accuracy:
[tensor(60.), tensor(62.2222), tensor(51.1364), tensor(53.4091), tensor(59.0909), tensor(62.9213), tensor(61.9565), tensor(49.4506), tensor(57.9545), tensor(47.7273)]
average accuracy 55.28510669708252
average loss 1.2635933075542356
average train accuracy: 57.10094303131103
average accuracy ct 57.320799560546874
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601]
training iter: 9 of 400
In this round, 10 clients are trained---->>>>
[77, 81, 52, 36, 74, 72, 50, 25, 68, 80]
Before Training, their test accuracy:
[array(62.92135, dtype=float32), array(56.81818, dtype=float32), array(61.53846, dtype=float32), array(54.444443, dtype=float32), array(62.637363, dtype=float32), array(53.260868, dtype=float32), array(57.142857, dtype=float32), array(47.727272, dtype=float32), array(56.179775, dtype=float32), array(57.77778, dtype=float32)]
After Finetune, their test accuracy:
[tensor(42.6966), tensor(40.9091), tensor(31.8681), tensor(52.2222), tensor(56.0440), tensor(33.6957), tensor(31.8681), tensor(28.4091), tensor(31.4607), tensor(42.2222)]
After distillation, their test accuracy:
[tensor(52.8090), tensor(53.4091), tensor(65.9341), tensor(52.2222), tensor(51.6483), tensor(45.6522), tensor(59.3407), tensor(47.7273), tensor(55.0562), tensor(52.2222)]
average accuracy 54.94083549499512
average loss 1.2807578369826516
average train accuracy: 56.95323001861572
average accuracy ct 57.11259960174561
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011]
training iter: 10 of 400
In this round, 10 clients are trained---->>>>
[53, 35, 67, 15, 55, 69, 83, 14, 79, 12]
Before Training, their test accuracy:
[array(45.555557, dtype=float32), array(46.153847, dtype=float32), array(51.612904, dtype=float32), array(44.94382, dtype=float32), array(60.674156, dtype=float32), array(64.83517, dtype=float32), array(56.666668, dtype=float32), array(61.53846, dtype=float32), array(53.333332, dtype=float32), array(47.727272, dtype=float32)]
After Finetune, their test accuracy:
[tensor(35.5556), tensor(39.5604), tensor(35.4839), tensor(32.5843), tensor(32.5843), tensor(42.8571), tensor(37.7778), tensor(56.0440), tensor(35.5556), tensor(40.9091)]
After distillation, their test accuracy:
[tensor(60.), tensor(49.4506), tensor(52.6882), tensor(55.0562), tensor(57.3034), tensor(57.1429), tensor(60.), tensor(56.0440), tensor(60.), tensor(45.4545)]
average accuracy 55.14181995391846
average loss 1.2888747784046222
average train accuracy: 57.002083969116214
average accuracy ct 57.168699684143064
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402]
training iter: 11 of 400
In this round, 10 clients are trained---->>>>
[13, 26, 71, 95, 4, 38, 0, 50, 85, 79]
Before Training, their test accuracy:
[array(48.35165, dtype=float32), array(56.179775, dtype=float32), array(60.674156, dtype=float32), array(55.555557, dtype=float32), array(49.45055, dtype=float32), array(50.57471, dtype=float32), array(48.88889, dtype=float32), array(59.34066, dtype=float32), array(44.94382, dtype=float32), array(60., dtype=float32)]
After Finetune, their test accuracy:
[tensor(41.7582), tensor(35.9551), tensor(40.4494), tensor(42.2222), tensor(38.4615), tensor(41.3793), tensor(36.6667), tensor(49.4506), tensor(23.5955), tensor(44.4444)]
After distillation, their test accuracy:
[tensor(64.8352), tensor(61.7978), tensor(56.1798), tensor(65.5556), tensor(51.6483), tensor(56.3218), tensor(45.5556), tensor(61.5385), tensor(51.6854), tensor(62.2222)]
average accuracy 55.57562297821045
average loss 1.2834851260155886
average train accuracy: 57.44645793914795
average accuracy ct 57.57279975891113
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952]
training iter: 12 of 400
In this round, 10 clients are trained---->>>>
[82, 96, 31, 17, 70, 86, 10, 92, 72, 57]
Before Training, their test accuracy:
[array(50.5618, dtype=float32), array(64.044945, dtype=float32), array(61.797752, dtype=float32), array(63.333332, dtype=float32), array(47.19101, dtype=float32), array(49.42529, dtype=float32), array(42.045456, dtype=float32), array(55.68182, dtype=float32), array(45.652172, dtype=float32), array(53.846153, dtype=float32)]
After Finetune, their test accuracy:
[tensor(44.9438), tensor(47.1910), tensor(53.9326), tensor(56.6667), tensor(34.8315), tensor(37.9310), tensor(35.2273), tensor(39.7727), tensor(47.8261), tensor(43.9560)]
After distillation, their test accuracy:
[tensor(53.9326), tensor(61.7978), tensor(52.8090), tensor(57.7778), tensor(51.6854), tensor(51.7241), tensor(54.5455), tensor(50.), tensor(54.3478), tensor(53.8462)]
average accuracy 55.66448642730713
average loss 1.2911107186596393
average train accuracy: 57.826720809936525
average accuracy ct 57.85649978637695
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546]
training iter: 13 of 400
In this round, 10 clients are trained---->>>>
[81, 52, 26, 77, 49, 20, 9, 56, 11, 19]
Before Training, their test accuracy:
[array(53.409092, dtype=float32), array(65.93407, dtype=float32), array(61.797752, dtype=float32), array(52.80899, dtype=float32), array(61.95652, dtype=float32), array(46.067417, dtype=float32), array(60., dtype=float32), array(58.426968, dtype=float32), array(46.067417, dtype=float32), array(60., dtype=float32)]
After Finetune, their test accuracy:
[tensor(59.0909), tensor(53.8462), tensor(42.6966), tensor(53.9326), tensor(46.7391), tensor(39.3258), tensor(48.8889), tensor(44.9438), tensor(30.3371), tensor(43.3333)]
After distillation, their test accuracy:
[tensor(48.8636), tensor(61.5385), tensor(64.0449), tensor(58.4270), tensor(63.0435), tensor(49.4382), tensor(56.6667), tensor(56.1798), tensor(51.6854), tensor(60.)]
average accuracy 55.69867946624756
average loss 1.3018319050710312
average train accuracy: 57.92054088592529
average accuracy ct 57.91679985046387
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149]
training iter: 14 of 400
In this round, 10 clients are trained---->>>>
[71, 64, 43, 17, 3, 45, 23, 56, 61, 73]
Before Training, their test accuracy:
[array(56.179775, dtype=float32), array(68.13187, dtype=float32), array(60., dtype=float32), array(57.77778, dtype=float32), array(51.64835, dtype=float32), array(55.05618, dtype=float32), array(58.88889, dtype=float32), array(56.179775, dtype=float32), array(56.666668, dtype=float32), array(62.365593, dtype=float32)]
After Finetune, their test accuracy:
[tensor(50.5618), tensor(50.5494), tensor(55.5556), tensor(55.5556), tensor(31.8681), tensor(35.9551), tensor(46.6667), tensor(51.6854), tensor(42.2222), tensor(40.8602)]
After distillation, their test accuracy:
[tensor(56.1798), tensor(61.5385), tensor(51.1111), tensor(56.6667), tensor(64.8352), tensor(51.6854), tensor(53.3333), tensor(51.6854), tensor(55.5556), tensor(49.4624)]
average accuracy 55.39026294708252
average loss 1.3249522005310002
average train accuracy: 57.989750442504885
average accuracy ct 57.831599922180175
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081]
training iter: 15 of 400
In this round, 10 clients are trained---->>>>
[45, 87, 39, 16, 73, 14, 38, 85, 17, 74]
Before Training, their test accuracy:
[array(51.685394, dtype=float32), array(50.5618, dtype=float32), array(46.067417, dtype=float32), array(55.172413, dtype=float32), array(49.462364, dtype=float32), array(56.043957, dtype=float32), array(56.32184, dtype=float32), array(51.685394, dtype=float32), array(56.666668, dtype=float32), array(51.64835, dtype=float32)]
After Finetune, their test accuracy:
[tensor(39.3258), tensor(48.3146), tensor(30.3371), tensor(39.0805), tensor(44.0860), tensor(45.0549), tensor(49.4253), tensor(44.9438), tensor(54.4444), tensor(48.3517)]
After distillation, their test accuracy:
[tensor(50.5618), tensor(51.6854), tensor(53.9326), tensor(49.4253), tensor(56.9892), tensor(60.4396), tensor(50.5747), tensor(56.1798), tensor(65.5556), tensor(58.2418)]
average accuracy 55.67296371459961
average loss 1.3222777829025336
average train accuracy: 58.009285888671876
average accuracy ct 58.008600006103514
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087]
training iter: 16 of 400
In this round, 10 clients are trained---->>>>
[89, 51, 83, 3, 38, 0, 87, 52, 30, 37]
Before Training, their test accuracy:
[array(64.83517, dtype=float32), array(62.22222, dtype=float32), array(60., dtype=float32), array(64.83517, dtype=float32), array(50.57471, dtype=float32), array(45.555557, dtype=float32), array(51.685394, dtype=float32), array(61.53846, dtype=float32), array(51.162792, dtype=float32), array(48.314606, dtype=float32)]
After Finetune, their test accuracy:
[tensor(47.2527), tensor(52.2222), tensor(54.4444), tensor(46.1538), tensor(47.1264), tensor(43.3333), tensor(57.3034), tensor(63.7363), tensor(38.3721), tensor(35.9551)]
After distillation, their test accuracy:
[tensor(58.2418), tensor(50.), tensor(65.5556), tensor(61.5385), tensor(64.3678), tensor(57.7778), tensor(55.0562), tensor(67.0330), tensor(52.3256), tensor(51.6854)]
average accuracy 55.90153781890869
average loss 1.3200725452384783
average train accuracy: 58.39811553955078
average accuracy ct 58.23980003356934
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085]
training iter: 17 of 400
In this round, 10 clients are trained---->>>>
[18, 95, 64, 98, 15, 57, 39, 67, 75, 14]
Before Training, their test accuracy:
[array(50.5618, dtype=float32), array(65.55556, dtype=float32), array(61.53846, dtype=float32), array(58.88889, dtype=float32), array(55.05618, dtype=float32), array(53.846153, dtype=float32), array(53.932583, dtype=float32), array(52.68817, dtype=float32), array(56.52174, dtype=float32), array(60.43956, dtype=float32)]
After Finetune, their test accuracy:
[tensor(37.0787), tensor(55.5556), tensor(49.4506), tensor(43.3333), tensor(39.3258), tensor(47.2527), tensor(41.5730), tensor(50.5376), tensor(43.4783), tensor(63.7363)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(56.6667), tensor(56.0440), tensor(53.3333), tensor(48.3146), tensor(56.0440), tensor(41.5730), tensor(61.2903), tensor(59.7826), tensor(63.7363)]
average accuracy 55.7521280670166
average loss 1.3367789651748965
average train accuracy: 58.331346321105954
average accuracy ct 58.067500076293946
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630]
training iter: 18 of 400
In this round, 10 clients are trained---->>>>
[24, 43, 30, 65, 32, 84, 27, 46, 21, 47]
Before Training, their test accuracy:
[array(53.932583, dtype=float32), array(51.11111, dtype=float32), array(52.32558, dtype=float32), array(59.34066, dtype=float32), array(60.91954, dtype=float32), array(51.11111, dtype=float32), array(50.54945, dtype=float32), array(56.179775, dtype=float32), array(62.22222, dtype=float32), array(66.666664, dtype=float32)]
After Finetune, their test accuracy:
[tensor(40.4494), tensor(54.4444), tensor(43.0233), tensor(50.5494), tensor(55.1724), tensor(37.7778), tensor(46.1538), tensor(47.1910), tensor(58.8889), tensor(51.1111)]
After distillation, their test accuracy:
[tensor(50.5618), tensor(63.3333), tensor(50.), tensor(41.7582), tensor(55.1724), tensor(56.6667), tensor(64.8352), tensor(43.8202), tensor(57.7778), tensor(61.1111)]
average accuracy 55.558908462524414
average loss 1.3535713725616736
average train accuracy: 58.26177474975586
average accuracy ct 58.117800064086914
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433]
training iter: 19 of 400
In this round, 10 clients are trained---->>>>
[8, 61, 70, 96, 56, 66, 24, 59, 2, 43]
Before Training, their test accuracy:
[array(56.179775, dtype=float32), array(55.555557, dtype=float32), array(51.685394, dtype=float32), array(61.797752, dtype=float32), array(51.685394, dtype=float32), array(56.179775, dtype=float32), array(50.5618, dtype=float32), array(53.409092, dtype=float32), array(41.573032, dtype=float32), array(63.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(37.0787), tensor(45.5556), tensor(46.0674), tensor(51.6854), tensor(47.1910), tensor(47.1910), tensor(41.5730), tensor(35.2273), tensor(28.0899), tensor(64.4444)]
After distillation, their test accuracy:
[tensor(49.4382), tensor(60.), tensor(55.0562), tensor(57.3034), tensor(52.8090), tensor(59.5506), tensor(56.1798), tensor(46.5909), tensor(39.3258), tensor(64.4444)]
average accuracy 55.54628215789795
average loss 1.3691176080117295
average train accuracy: 58.351566772460934
average accuracy ct 58.1042000579834
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057]
training iter: 20 of 400
In this round, 10 clients are trained---->>>>
[36, 11, 5, 51, 70, 99, 26, 47, 25, 74]
Before Training, their test accuracy:
[array(52.22222, dtype=float32), array(51.685394, dtype=float32), array(52.272728, dtype=float32), array(50., dtype=float32), array(55.05618, dtype=float32), array(60., dtype=float32), array(64.044945, dtype=float32), array(61.11111, dtype=float32), array(47.727272, dtype=float32), array(58.241756, dtype=float32)]
After Finetune, their test accuracy:
[tensor(52.2222), tensor(37.0787), tensor(30.6818), tensor(54.4444), tensor(47.1910), tensor(33.3333), tensor(51.6854), tensor(53.3333), tensor(40.9091), tensor(51.6483)]
After distillation, their test accuracy:
[tensor(57.7778), tensor(55.0562), tensor(42.0455), tensor(58.8889), tensor(44.9438), tensor(68.8889), tensor(58.4270), tensor(62.2222), tensor(50.), tensor(57.1429)]
average accuracy 55.576596641540526
average loss 1.387101687964484
average train accuracy: 58.39158657073975
average accuracy ct 58.154799995422366
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054]
training iter: 21 of 400
In this round, 10 clients are trained---->>>>
[35, 11, 1, 86, 59, 97, 82, 6, 13, 93]
Before Training, their test accuracy:
[array(49.45055, dtype=float32), array(55.05618, dtype=float32), array(57.77778, dtype=float32), array(51.724136, dtype=float32), array(46.590908, dtype=float32), array(49.4382, dtype=float32), array(53.932583, dtype=float32), array(53.932583, dtype=float32), array(64.83517, dtype=float32), array(53.409092, dtype=float32)]
After Finetune, their test accuracy:
[tensor(45.0549), tensor(40.4494), tensor(42.2222), tensor(42.5287), tensor(42.0455), tensor(33.7079), tensor(50.5618), tensor(48.3146), tensor(61.5385), tensor(39.7727)]
After distillation, their test accuracy:
[tensor(56.0440), tensor(59.5506), tensor(68.8889), tensor(56.3218), tensor(44.3182), tensor(53.9326), tensor(59.5506), tensor(52.8090), tensor(67.0330), tensor(56.8182)]
average accuracy 55.96779186248779
average loss 1.3868131840892461
average train accuracy: 58.25086181640625
average accuracy ct 58.17540004730225
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885]
training iter: 22 of 400
In this round, 10 clients are trained---->>>>
[71, 57, 82, 7, 13, 46, 79, 90, 47, 3]
Before Training, their test accuracy:
[array(56.179775, dtype=float32), array(56.043957, dtype=float32), array(59.55056, dtype=float32), array(61.363636, dtype=float32), array(67.03297, dtype=float32), array(43.820225, dtype=float32), array(62.22222, dtype=float32), array(57.77778, dtype=float32), array(62.22222, dtype=float32), array(61.53846, dtype=float32)]
After Finetune, their test accuracy:
[tensor(55.0562), tensor(49.4506), tensor(61.7978), tensor(61.3636), tensor(68.1319), tensor(48.3146), tensor(46.6667), tensor(32.2222), tensor(61.1111), tensor(57.1429)]
After distillation, their test accuracy:
[tensor(48.3146), tensor(54.9451), tensor(58.4270), tensor(64.7727), tensor(65.9341), tensor(48.3146), tensor(64.4444), tensor(63.3333), tensor(62.2222), tensor(59.3407)]
average accuracy 55.99076068878174
average loss 1.4088745841129762
average train accuracy: 58.49691860198975
average accuracy ct 58.37860000610352
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221]
training iter: 23 of 400
In this round, 10 clients are trained---->>>>
[96, 17, 80, 66, 75, 59, 92, 56, 34, 12]
Before Training, their test accuracy:
[array(57.30337, dtype=float32), array(65.55556, dtype=float32), array(52.22222, dtype=float32), array(59.55056, dtype=float32), array(59.782608, dtype=float32), array(44.31818, dtype=float32), array(50., dtype=float32), array(52.80899, dtype=float32), array(60.215054, dtype=float32), array(45.454544, dtype=float32)]
After Finetune, their test accuracy:
[tensor(58.4270), tensor(60.), tensor(47.7778), tensor(43.8202), tensor(54.3478), tensor(45.4545), tensor(54.5455), tensor(50.5618), tensor(45.1613), tensor(50.)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(60.), tensor(56.6667), tensor(59.5506), tensor(64.1304), tensor(44.3182), tensor(53.4091), tensor(51.6854), tensor(56.9892), tensor(53.4091)]
average accuracy 56.09327018737793
average loss 1.4226476955035985
average train accuracy: 58.80938617706299
average accuracy ct 58.6346000289917
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899]
training iter: 24 of 400
In this round, 10 clients are trained---->>>>
[52, 10, 30, 23, 14, 26, 5, 7, 60, 59]
Before Training, their test accuracy:
[array(67.03297, dtype=float32), array(54.545456, dtype=float32), array(50., dtype=float32), array(53.333332, dtype=float32), array(63.736263, dtype=float32), array(58.426968, dtype=float32), array(42.045456, dtype=float32), array(64.77273, dtype=float32), array(62.22222, dtype=float32), array(44.31818, dtype=float32)]
After Finetune, their test accuracy:
[tensor(69.2308), tensor(46.5909), tensor(53.4884), tensor(58.8889), tensor(61.5385), tensor(61.7978), tensor(23.8636), tensor(62.5000), tensor(37.7778), tensor(51.1364)]
After distillation, their test accuracy:
[tensor(57.1429), tensor(47.7273), tensor(51.1628), tensor(63.3333), tensor(61.5385), tensor(57.3034), tensor(48.8636), tensor(65.9091), tensor(61.1111), tensor(48.8636)]
average accuracy 56.118490028381345
average loss 1.4312940189609535
average train accuracy: 59.04664794921875
average accuracy ct 58.817100067138675
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193]
training iter: 25 of 400
In this round, 10 clients are trained---->>>>
[59, 69, 57, 29, 33, 42, 21, 48, 22, 1]
Before Training, their test accuracy:
[array(48.863636, dtype=float32), array(57.142857, dtype=float32), array(54.945053, dtype=float32), array(57.954544, dtype=float32), array(42.69663, dtype=float32), array(59.34066, dtype=float32), array(57.77778, dtype=float32), array(59.090908, dtype=float32), array(54.022987, dtype=float32), array(68.888885, dtype=float32)]
After Finetune, their test accuracy:
[tensor(47.7273), tensor(56.0440), tensor(51.6483), tensor(57.9545), tensor(31.4607), tensor(37.3626), tensor(56.6667), tensor(50.), tensor(32.1839), tensor(60.)]
After distillation, their test accuracy:
[tensor(55.6818), tensor(69.2308), tensor(60.4396), tensor(59.0909), tensor(49.4382), tensor(49.4506), tensor(71.1111), tensor(59.0909), tensor(47.1264), tensor(57.7778)]
average accuracy 56.295631103515625
average loss 1.4324495373776545
average train accuracy: 59.17736782073975
average accuracy ct 58.971500091552734
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754]
training iter: 26 of 400
In this round, 10 clients are trained---->>>>
[37, 46, 6, 0, 81, 72, 22, 30, 39, 8]
Before Training, their test accuracy:
[array(51.685394, dtype=float32), array(48.314606, dtype=float32), array(52.80899, dtype=float32), array(57.77778, dtype=float32), array(48.863636, dtype=float32), array(54.347828, dtype=float32), array(47.12644, dtype=float32), array(51.162792, dtype=float32), array(41.573032, dtype=float32), array(49.4382, dtype=float32)]
After Finetune, their test accuracy:
[tensor(49.4382), tensor(52.8090), tensor(49.4382), tensor(45.5556), tensor(47.7273), tensor(59.7826), tensor(44.8276), tensor(51.1628), tensor(44.9438), tensor(42.6966)]
After distillation, their test accuracy:
[tensor(51.6854), tensor(52.8090), tensor(47.1910), tensor(53.3333), tensor(47.7273), tensor(58.6957), tensor(51.7241), tensor(51.1628), tensor(44.9438), tensor(50.5618)]
average accuracy 56.36298610687256
average loss 1.4459265794917706
average train accuracy: 59.35148426055908
average accuracy ct 59.085000076293944
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502]
training iter: 27 of 400
In this round, 10 clients are trained---->>>>
[17, 42, 53, 76, 62, 11, 72, 33, 12, 46]
Before Training, their test accuracy:
[array(60., dtype=float32), array(49.45055, dtype=float32), array(60., dtype=float32), array(55.555557, dtype=float32), array(51.136364, dtype=float32), array(59.55056, dtype=float32), array(58.695652, dtype=float32), array(49.4382, dtype=float32), array(53.409092, dtype=float32), array(52.80899, dtype=float32)]
After Finetune, their test accuracy:
[tensor(55.5556), tensor(40.6593), tensor(47.7778), tensor(48.8889), tensor(47.7273), tensor(62.9213), tensor(54.3478), tensor(48.3146), tensor(47.7273), tensor(55.0562)]
After distillation, their test accuracy:
[tensor(60.), tensor(61.5385), tensor(62.2222), tensor(62.2222), tensor(62.5000), tensor(59.5506), tensor(55.4348), tensor(55.0562), tensor(54.5455), tensor(62.9213)]
average accuracy 56.82244873046875
average loss 1.4416190329836172
average train accuracy: 59.38482791900635
average accuracy ct 59.171799964904785
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379]
training iter: 28 of 400
In this round, 10 clients are trained---->>>>
[72, 78, 19, 7, 29, 33, 13, 56, 94, 64]
Before Training, their test accuracy:
[array(55.434784, dtype=float32), array(47.252747, dtype=float32), array(60., dtype=float32), array(65.90909, dtype=float32), array(59.090908, dtype=float32), array(55.05618, dtype=float32), array(65.93407, dtype=float32), array(51.685394, dtype=float32), array(64.51613, dtype=float32), array(56.043957, dtype=float32)]
After Finetune, their test accuracy:
[tensor(55.4348), tensor(47.2527), tensor(48.8889), tensor(60.2273), tensor(57.9545), tensor(55.0562), tensor(67.0330), tensor(51.6854), tensor(32.2581), tensor(62.6374)]
After distillation, their test accuracy:
[tensor(60.8696), tensor(59.3407), tensor(55.5556), tensor(60.2273), tensor(51.1364), tensor(49.4382), tensor(67.0330), tensor(57.3034), tensor(65.5914), tensor(62.6374)]
average accuracy 56.90454341888428
average loss 1.4456407637543176
average train accuracy: 59.49888442993164
average accuracy ct 59.32879997253418
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358]
training iter: 29 of 400
In this round, 10 clients are trained---->>>>
[17, 27, 26, 22, 7, 62, 44, 69, 45, 80]
Before Training, their test accuracy:
[array(60., dtype=float32), array(64.83517, dtype=float32), array(57.30337, dtype=float32), array(51.724136, dtype=float32), array(60.227272, dtype=float32), array(62.5, dtype=float32), array(50.5618, dtype=float32), array(69.23077, dtype=float32), array(50.5618, dtype=float32), array(56.666668, dtype=float32)]
After Finetune, their test accuracy:
[tensor(63.3333), tensor(50.5494), tensor(56.1798), tensor(49.4253), tensor(59.0909), tensor(54.5455), tensor(40.4494), tensor(50.5494), tensor(46.0674), tensor(55.5556)]
After distillation, their test accuracy:
[tensor(53.3333), tensor(60.4396), tensor(55.0562), tensor(52.8736), tensor(63.6364), tensor(54.5455), tensor(55.0562), tensor(58.2418), tensor(52.8090), tensor(56.6667)]
average accuracy 56.69501411437988
average loss 1.4645855368495975
average train accuracy: 59.57138126373291
average accuracy ct 59.42269992828369
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788]
training iter: 30 of 400
In this round, 10 clients are trained---->>>>
[72, 5, 95, 84, 51, 8, 58, 88, 94, 83]
Before Training, their test accuracy:
[array(60.869564, dtype=float32), array(48.863636, dtype=float32), array(56.666668, dtype=float32), array(56.666668, dtype=float32), array(58.88889, dtype=float32), array(50.5618, dtype=float32), array(49.4382, dtype=float32), array(63.04348, dtype=float32), array(65.5914, dtype=float32), array(65.55556, dtype=float32)]
After Finetune, their test accuracy:
[tensor(58.6957), tensor(53.4091), tensor(60.), tensor(47.7778), tensor(55.5556), tensor(55.0562), tensor(42.6966), tensor(53.2609), tensor(55.9140), tensor(47.7778)]
After distillation, their test accuracy:
[tensor(56.5217), tensor(52.2727), tensor(61.1111), tensor(60.), tensor(63.3333), tensor(52.8090), tensor(51.6854), tensor(60.8696), tensor(61.2903), tensor(54.4444)]
average accuracy 56.67693172454834
average loss 1.4754520306179382
average train accuracy: 59.56334812164307
average accuracy ct 59.43399982452392
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323]
training iter: 31 of 400
In this round, 10 clients are trained---->>>>
[77, 65, 84, 57, 55, 78, 68, 28, 83, 85]
Before Training, their test accuracy:
[array(58.426968, dtype=float32), array(41.758244, dtype=float32), array(60., dtype=float32), array(60.43956, dtype=float32), array(57.30337, dtype=float32), array(59.34066, dtype=float32), array(55.05618, dtype=float32), array(55.555557, dtype=float32), array(54.444443, dtype=float32), array(56.179775, dtype=float32)]
After Finetune, their test accuracy:
[tensor(58.4270), tensor(45.0549), tensor(46.6667), tensor(56.0440), tensor(53.9326), tensor(48.3517), tensor(46.0674), tensor(43.3333), tensor(50.), tensor(42.6966)]
After distillation, their test accuracy:
[tensor(53.9326), tensor(59.3407), tensor(54.4444), tensor(53.8462), tensor(55.0562), tensor(59.3407), tensor(60.6742), tensor(65.5556), tensor(56.6667), tensor(57.3034)]
average accuracy 56.85348846435547
average loss 1.4811915257562518
average train accuracy: 59.74935424804688
average accuracy ct 59.617499885559084
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080]
training iter: 32 of 400
In this round, 10 clients are trained---->>>>
[50, 95, 79, 51, 52, 39, 75, 64, 98, 17]
Before Training, their test accuracy:
[array(61.53846, dtype=float32), array(61.11111, dtype=float32), array(64.44444, dtype=float32), array(63.333332, dtype=float32), array(57.142857, dtype=float32), array(44.94382, dtype=float32), array(64.13043, dtype=float32), array(62.637363, dtype=float32), array(53.333332, dtype=float32), array(53.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(56.0440), tensor(62.2222), tensor(63.3333), tensor(65.5556), tensor(58.2418), tensor(49.4382), tensor(63.0435), tensor(60.4396), tensor(51.1111), tensor(58.8889)]
After distillation, their test accuracy:
[tensor(48.3517), tensor(66.6667), tensor(70.), tensor(58.8889), tensor(65.9341), tensor(49.4382), tensor(59.7826), tensor(62.6374), tensor(57.7778), tensor(62.2222)]
average accuracy 57.01099807739258
average loss 1.4801189799734857
average train accuracy: 59.81599075317383
average accuracy ct 59.57079978942871
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366]
training iter: 33 of 400
In this round, 10 clients are trained---->>>>
[15, 31, 94, 41, 70, 62, 51, 1, 89, 84]
Before Training, their test accuracy:
[array(48.314606, dtype=float32), array(52.80899, dtype=float32), array(61.29032, dtype=float32), array(57.142857, dtype=float32), array(44.94382, dtype=float32), array(54.545456, dtype=float32), array(58.88889, dtype=float32), array(57.77778, dtype=float32), array(58.241756, dtype=float32), array(54.444443, dtype=float32)]
After Finetune, their test accuracy:
[tensor(47.1910), tensor(53.9326), tensor(50.5376), tensor(42.8571), tensor(49.4382), tensor(52.2727), tensor(61.1111), tensor(53.3333), tensor(47.2527), tensor(52.2222)]
After distillation, their test accuracy:
[tensor(51.6854), tensor(53.9326), tensor(54.8387), tensor(59.3407), tensor(52.8090), tensor(59.0909), tensor(56.6667), tensor(73.3333), tensor(60.4396), tensor(55.5556)]
average accuracy 57.30393257141113
average loss 1.4809757782750725
average train accuracy: 60.08997211456299
average accuracy ct 59.76589981079101
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328]
training iter: 34 of 400
In this round, 10 clients are trained---->>>>
[65, 78, 39, 94, 70, 11, 68, 92, 98, 82]
Before Training, their test accuracy:
[array(59.34066, dtype=float32), array(59.34066, dtype=float32), array(49.4382, dtype=float32), array(54.83871, dtype=float32), array(52.80899, dtype=float32), array(59.55056, dtype=float32), array(60.674156, dtype=float32), array(53.409092, dtype=float32), array(57.77778, dtype=float32), array(58.426968, dtype=float32)]
After Finetune, their test accuracy:
[tensor(59.3407), tensor(58.2418), tensor(46.0674), tensor(54.8387), tensor(51.6854), tensor(55.0562), tensor(59.5506), tensor(51.1364), tensor(57.7778), tensor(59.5506)]
After distillation, their test accuracy:
[tensor(61.5385), tensor(60.4396), tensor(58.4270), tensor(61.2903), tensor(51.6854), tensor(62.9213), tensor(58.4270), tensor(55.6818), tensor(54.4444), tensor(52.8090)]
average accuracy 57.424517517089846
average loss 1.4905095408674247
average train accuracy: 60.23667839050293
average accuracy ct 59.940499801635745
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525]
training iter: 35 of 400
In this round, 10 clients are trained---->>>>
[47, 34, 1, 42, 62, 73, 50, 43, 56, 76]
Before Training, their test accuracy:
[array(62.22222, dtype=float32), array(56.989246, dtype=float32), array(73.333336, dtype=float32), array(61.53846, dtype=float32), array(59.090908, dtype=float32), array(56.989246, dtype=float32), array(48.35165, dtype=float32), array(64.44444, dtype=float32), array(57.30337, dtype=float32), array(62.22222, dtype=float32)]
After Finetune, their test accuracy:
[tensor(60.), tensor(52.6882), tensor(71.1111), tensor(54.9451), tensor(60.2273), tensor(54.8387), tensor(49.4506), tensor(60.), tensor(56.1798), tensor(60.)]
After distillation, their test accuracy:
[tensor(68.8889), tensor(55.9140), tensor(66.6667), tensor(58.2418), tensor(55.6818), tensor(52.6882), tensor(53.8462), tensor(60.), tensor(58.4270), tensor(68.8889)]
average accuracy 57.39209930419922
average loss 1.4987141672455604
average train accuracy: 60.3529623413086
average accuracy ct 60.01089984893799
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180]
training iter: 36 of 400
In this round, 10 clients are trained---->>>>
[34, 0, 24, 36, 16, 80, 52, 32, 22, 39]
Before Training, their test accuracy:
[array(55.91398, dtype=float32), array(53.333332, dtype=float32), array(56.179775, dtype=float32), array(57.77778, dtype=float32), array(49.42529, dtype=float32), array(56.666668, dtype=float32), array(65.93407, dtype=float32), array(55.172413, dtype=float32), array(52.87356, dtype=float32), array(58.426968, dtype=float32)]
After Finetune, their test accuracy:
[tensor(58.0645), tensor(51.1111), tensor(55.0562), tensor(65.5556), tensor(41.3793), tensor(51.1111), tensor(63.7363), tensor(52.8736), tensor(49.4253), tensor(56.1798)]
After distillation, their test accuracy:
[tensor(50.5376), tensor(60.), tensor(64.0449), tensor(58.8889), tensor(54.0230), tensor(61.1111), tensor(67.0330), tensor(59.7701), tensor(45.9770), tensor(51.6854)]
average accuracy 57.50577156066895
average loss 1.4998315948209808
average train accuracy: 60.519708137512204
average accuracy ct 60.13259994506836
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720]
training iter: 37 of 400
In this round, 10 clients are trained---->>>>
[47, 53, 28, 24, 83, 62, 50, 94, 55, 90]
Before Training, their test accuracy:
[array(68.888885, dtype=float32), array(62.22222, dtype=float32), array(65.55556, dtype=float32), array(64.044945, dtype=float32), array(56.666668, dtype=float32), array(55.68182, dtype=float32), array(53.846153, dtype=float32), array(61.29032, dtype=float32), array(55.05618, dtype=float32), array(63.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(62.2222), tensor(55.5556), tensor(53.3333), tensor(65.1685), tensor(55.5556), tensor(59.0909), tensor(51.6483), tensor(60.2151), tensor(55.0562), tensor(53.3333)]
After distillation, their test accuracy:
[tensor(61.1111), tensor(57.7778), tensor(64.4444), tensor(58.4270), tensor(65.5556), tensor(57.9545), tensor(57.1429), tensor(67.7419), tensor(58.4270), tensor(67.7778)]
average accuracy 57.60351013183594
average loss 1.5032991555182955
average train accuracy: 60.666029090881345
average accuracy ct 60.23719989776611
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105]
training iter: 38 of 400
In this round, 10 clients are trained---->>>>
[93, 16, 62, 32, 59, 38, 4, 44, 60, 30]
Before Training, their test accuracy:
[array(56.81818, dtype=float32), array(54.022987, dtype=float32), array(57.954544, dtype=float32), array(59.770115, dtype=float32), array(55.68182, dtype=float32), array(64.36781, dtype=float32), array(51.64835, dtype=float32), array(55.05618, dtype=float32), array(61.11111, dtype=float32), array(51.162792, dtype=float32)]
After Finetune, their test accuracy:
[tensor(50.), tensor(51.7241), tensor(53.4091), tensor(59.7701), tensor(54.5455), tensor(60.9195), tensor(41.7582), tensor(51.6854), tensor(50.), tensor(47.6744)]
After distillation, their test accuracy:
[tensor(59.0909), tensor(55.1724), tensor(56.8182), tensor(51.7241), tensor(50.), tensor(62.0690), tensor(61.5385), tensor(48.3146), tensor(53.3333), tensor(58.1395)]
average accuracy 57.48957656860352
average loss 1.5198381926531974
average train accuracy: 60.79144439697266
average accuracy ct 60.297499923706056
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405]
training iter: 39 of 400
In this round, 10 clients are trained---->>>>
[82, 78, 97, 86, 27, 47, 54, 38, 95, 49]
Before Training, their test accuracy:
[array(52.80899, dtype=float32), array(60.43956, dtype=float32), array(53.932583, dtype=float32), array(56.32184, dtype=float32), array(60.43956, dtype=float32), array(61.11111, dtype=float32), array(64.83517, dtype=float32), array(62.068966, dtype=float32), array(66.666664, dtype=float32), array(63.04348, dtype=float32)]
After Finetune, their test accuracy:
[tensor(57.3034), tensor(59.3407), tensor(43.8202), tensor(40.2299), tensor(56.0440), tensor(63.3333), tensor(50.5494), tensor(58.6207), tensor(64.4444), tensor(64.1304)]
After distillation, their test accuracy:
[tensor(58.4270), tensor(60.4396), tensor(57.3034), tensor(56.3218), tensor(64.8352), tensor(60.), tensor(63.7363), tensor(66.6667), tensor(62.2222), tensor(61.9565)]
average accuracy 57.59198310852051
average loss 1.516561992033418
average train accuracy: 60.802087020874026
average accuracy ct 60.37009990692139
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108]
training iter: 40 of 400
In this round, 10 clients are trained---->>>>
[41, 37, 17, 86, 67, 71, 36, 11, 57, 79]
Before Training, their test accuracy:
[array(59.34066, dtype=float32), array(51.685394, dtype=float32), array(62.22222, dtype=float32), array(56.32184, dtype=float32), array(61.29032, dtype=float32), array(48.314606, dtype=float32), array(58.88889, dtype=float32), array(62.92135, dtype=float32), array(53.846153, dtype=float32), array(70., dtype=float32)]
After Finetune, their test accuracy:
[tensor(56.0440), tensor(44.9438), tensor(62.2222), tensor(51.7241), tensor(45.1613), tensor(41.5730), tensor(62.2222), tensor(61.7978), tensor(57.1429), tensor(68.8889)]
After distillation, their test accuracy:
[tensor(59.3407), tensor(59.5506), tensor(60.), tensor(48.2759), tensor(55.9140), tensor(52.8090), tensor(56.6667), tensor(59.5506), tensor(61.5385), tensor(60.)]
average accuracy 57.480126190185544
average loss 1.5370336344627111
average train accuracy: 60.836422996520994
average accuracy ct 60.37549991607666
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328]
training iter: 41 of 400
In this round, 10 clients are trained---->>>>
[20, 58, 12, 0, 1, 86, 68, 2, 13, 23]
Before Training, their test accuracy:
[array(49.4382, dtype=float32), array(51.685394, dtype=float32), array(54.545456, dtype=float32), array(60., dtype=float32), array(66.666664, dtype=float32), array(48.275864, dtype=float32), array(58.426968, dtype=float32), array(39.325844, dtype=float32), array(67.03297, dtype=float32), array(63.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(50.5618), tensor(50.5618), tensor(54.5455), tensor(63.3333), tensor(61.1111), tensor(49.4253), tensor(56.1798), tensor(39.3258), tensor(69.2308), tensor(65.5556)]
After distillation, their test accuracy:
[tensor(53.9326), tensor(49.4382), tensor(53.4091), tensor(64.4444), tensor(70.), tensor(51.7241), tensor(64.0449), tensor(55.0562), tensor(69.2308), tensor(62.2222)]
average accuracy 57.82784496307373
average loss 1.5330001434488012
average train accuracy: 60.914876289367676
average accuracy ct 60.48539993286133
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761]
training iter: 42 of 400
In this round, 10 clients are trained---->>>>
[55, 26, 54, 59, 67, 13, 58, 61, 33, 0]
Before Training, their test accuracy:
[array(58.426968, dtype=float32), array(55.05618, dtype=float32), array(63.736263, dtype=float32), array(50., dtype=float32), array(55.91398, dtype=float32), array(69.23077, dtype=float32), array(49.4382, dtype=float32), array(60., dtype=float32), array(49.4382, dtype=float32), array(64.44444, dtype=float32)]
After Finetune, their test accuracy:
[tensor(52.8090), tensor(49.4382), tensor(57.1429), tensor(52.2727), tensor(50.5376), tensor(67.0330), tensor(48.3146), tensor(55.5556), tensor(51.6854), tensor(61.1111)]
After distillation, their test accuracy:
[tensor(61.7978), tensor(60.6742), tensor(59.3407), tensor(45.4545), tensor(59.1398), tensor(70.3297), tensor(52.8090), tensor(55.5556), tensor(50.5618), tensor(63.3333)]
average accuracy 57.8609574508667
average loss 1.5466613504987077
average train accuracy: 60.96305648803711
average accuracy ct 60.52409999847412
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565]
training iter: 43 of 400
In this round, 10 clients are trained---->>>>
[3, 4, 5, 92, 56, 72, 18, 61, 16, 89]
Before Training, their test accuracy:
[array(59.34066, dtype=float32), array(61.53846, dtype=float32), array(52.272728, dtype=float32), array(55.68182, dtype=float32), array(58.426968, dtype=float32), array(56.52174, dtype=float32), array(57.30337, dtype=float32), array(55.555557, dtype=float32), array(55.172413, dtype=float32), array(60.43956, dtype=float32)]
After Finetune, their test accuracy:
[tensor(62.6374), tensor(61.5385), tensor(53.4091), tensor(54.5455), tensor(56.1798), tensor(58.6957), tensor(55.0562), tensor(47.7778), tensor(54.0230), tensor(48.3517)]
After distillation, their test accuracy:
[tensor(58.2418), tensor(49.4506), tensor(54.5455), tensor(45.4545), tensor(52.8090), tensor(59.7826), tensor(56.1798), tensor(63.3333), tensor(58.6207), tensor(57.1429)]
average accuracy 57.6940302658081
average loss 1.5628178995393507
average train accuracy: 61.042947921752926
average accuracy ct 60.73579998016358
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977]
training iter: 44 of 400
In this round, 10 clients are trained---->>>>
[45, 76, 77, 35, 87, 20, 51, 22, 26, 2]
Before Training, their test accuracy:
[array(52.80899, dtype=float32), array(68.888885, dtype=float32), array(53.932583, dtype=float32), array(56.043957, dtype=float32), array(55.05618, dtype=float32), array(53.932583, dtype=float32), array(56.666668, dtype=float32), array(45.977013, dtype=float32), array(60.674156, dtype=float32), array(55.05618, dtype=float32)]
After Finetune, their test accuracy:
[tensor(51.6854), tensor(65.5556), tensor(56.1798), tensor(58.2418), tensor(56.1798), tensor(49.4382), tensor(61.1111), tensor(48.2759), tensor(59.5506), tensor(46.0674)]
After distillation, their test accuracy:
[tensor(58.4270), tensor(60.), tensor(56.1798), tensor(54.9451), tensor(60.6742), tensor(57.3034), tensor(57.7778), tensor(48.2759), tensor(56.1798), tensor(51.6854)]
average accuracy 57.71813968658447
average loss 1.5785947294749607
average train accuracy: 61.09198516845703
average accuracy ct 60.86770004272461
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954]
training iter: 45 of 400
In this round, 10 clients are trained---->>>>
[45, 37, 46, 28, 92, 26, 38, 4, 73, 55]
Before Training, their test accuracy:
[array(58.426968, dtype=float32), array(59.55056, dtype=float32), array(62.92135, dtype=float32), array(64.44444, dtype=float32), array(45.454544, dtype=float32), array(56.179775, dtype=float32), array(66.666664, dtype=float32), array(49.45055, dtype=float32), array(52.68817, dtype=float32), array(61.797752, dtype=float32)]
After Finetune, their test accuracy:
[tensor(56.1798), tensor(55.0562), tensor(60.6742), tensor(56.6667), tensor(53.4091), tensor(56.1798), tensor(66.6667), tensor(47.2527), tensor(54.8387), tensor(58.4270)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(56.1798), tensor(55.0562), tensor(60.), tensor(55.6818), tensor(58.4270), tensor(64.3678), tensor(58.2418), tensor(62.3656), tensor(58.4270)]
average accuracy 57.802834358215335
average loss 1.5880988815222385
average train accuracy: 61.177403602600094
average accuracy ct 60.969000091552736
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042]
training iter: 46 of 400
In this round, 10 clients are trained---->>>>
[76, 14, 25, 96, 86, 59, 57, 50, 88, 74]
Before Training, their test accuracy:
[array(60., dtype=float32), array(61.53846, dtype=float32), array(50., dtype=float32), array(57.30337, dtype=float32), array(51.724136, dtype=float32), array(45.454544, dtype=float32), array(61.53846, dtype=float32), array(57.142857, dtype=float32), array(60.869564, dtype=float32), array(57.142857, dtype=float32)]
After Finetune, their test accuracy:
[tensor(63.3333), tensor(58.2418), tensor(57.9545), tensor(60.6742), tensor(49.4253), tensor(51.1364), tensor(63.7363), tensor(54.9451), tensor(47.8261), tensor(60.4396)]
After distillation, their test accuracy:
[tensor(57.7778), tensor(59.3407), tensor(46.5909), tensor(64.0449), tensor(50.5747), tensor(50.), tensor(59.3407), tensor(61.5385), tensor(59.7826), tensor(61.5385)]
average accuracy 57.88098377227783
average loss 1.5932872615088152
average train accuracy: 61.2523751449585
average accuracy ct 60.993200073242186
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833]
training iter: 47 of 400
In this round, 10 clients are trained---->>>>
[12, 52, 72, 17, 78, 64, 71, 84, 95, 61]
Before Training, their test accuracy:
[array(53.409092, dtype=float32), array(67.03297, dtype=float32), array(59.782608, dtype=float32), array(60., dtype=float32), array(60.43956, dtype=float32), array(62.637363, dtype=float32), array(52.80899, dtype=float32), array(55.555557, dtype=float32), array(62.22222, dtype=float32), array(63.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(55.6818), tensor(69.2308), tensor(59.7826), tensor(62.2222), tensor(61.5385), tensor(56.0440), tensor(58.4270), tensor(58.8889), tensor(62.2222), tensor(67.7778)]
After distillation, their test accuracy:
[tensor(51.1364), tensor(64.8352), tensor(59.7826), tensor(65.5556), tensor(62.6374), tensor(64.8352), tensor(51.6854), tensor(56.6667), tensor(63.3333), tensor(66.6667)]
average accuracy 57.98010971069336
average loss 1.6001575317259655
average train accuracy: 61.27715358734131
average accuracy ct 60.95470008850098
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245]
training iter: 48 of 400
In this round, 10 clients are trained---->>>>
[88, 68, 86, 62, 83, 23, 59, 21, 87, 82]
Before Training, their test accuracy:
[array(59.782608, dtype=float32), array(64.044945, dtype=float32), array(50.57471, dtype=float32), array(56.81818, dtype=float32), array(65.55556, dtype=float32), array(62.22222, dtype=float32), array(50., dtype=float32), array(71.111115, dtype=float32), array(60.674156, dtype=float32), array(58.426968, dtype=float32)]
After Finetune, their test accuracy:
[tensor(60.8696), tensor(62.9213), tensor(55.1724), tensor(54.5455), tensor(66.6667), tensor(60.), tensor(52.2727), tensor(66.6667), tensor(58.4270), tensor(52.8090)]
After distillation, their test accuracy:
[tensor(67.3913), tensor(56.1798), tensor(55.1724), tensor(60.2273), tensor(68.8889), tensor(72.2222), tensor(52.2727), tensor(66.6667), tensor(58.4270), tensor(59.5506)]
average accuracy 58.15799301147461
average loss 1.5986676389082044
average train accuracy: 61.38775100708008
average accuracy ct 61.07480003356934
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336, 58.15799301147461]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131, 61.38775100708008]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098, 61.07480003356934]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245, 60690165]
training iter: 49 of 400
In this round, 10 clients are trained---->>>>
[18, 99, 72, 32, 30, 87, 34, 46, 78, 2]
Before Training, their test accuracy:
[array(56.179775, dtype=float32), array(68.888885, dtype=float32), array(59.782608, dtype=float32), array(51.724136, dtype=float32), array(58.139534, dtype=float32), array(58.426968, dtype=float32), array(50.537636, dtype=float32), array(55.05618, dtype=float32), array(62.637363, dtype=float32), array(51.685394, dtype=float32)]
After Finetune, their test accuracy:
[tensor(64.0449), tensor(46.6667), tensor(60.8696), tensor(64.3678), tensor(55.8140), tensor(56.1798), tensor(52.6882), tensor(52.8090), tensor(62.6374), tensor(55.0562)]
After distillation, their test accuracy:
[tensor(57.3034), tensor(65.5556), tensor(64.1304), tensor(55.1724), tensor(54.6512), tensor(59.5506), tensor(58.0645), tensor(64.0449), tensor(64.8352), tensor(49.4382)]
average accuracy 58.35487148284912
average loss 1.5986699555809545
average train accuracy: 61.35578327178955
average accuracy ct 61.06450000762939
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336, 58.15799301147461, 58.35487148284912]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131, 61.38775100708008, 61.35578327178955]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098, 61.07480003356934, 61.06450000762939]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245, 60690165, 57040452]
training iter: 50 of 400
In this round, 10 clients are trained---->>>>
[94, 31, 34, 40, 90, 23, 88, 24, 2, 60]
Before Training, their test accuracy:
[array(67.741936, dtype=float32), array(53.932583, dtype=float32), array(58.064518, dtype=float32), array(54.545456, dtype=float32), array(67.77778, dtype=float32), array(72.22222, dtype=float32), array(67.391304, dtype=float32), array(58.426968, dtype=float32), array(49.4382, dtype=float32), array(53.333332, dtype=float32)]
After Finetune, their test accuracy:
[tensor(61.2903), tensor(52.8090), tensor(55.9140), tensor(43.1818), tensor(60.), tensor(70.), tensor(61.9565), tensor(55.0562), tensor(51.6854), tensor(51.1111)]
After distillation, their test accuracy:
[tensor(62.3656), tensor(53.9326), tensor(60.2151), tensor(57.9545), tensor(63.3333), tensor(65.5556), tensor(67.3913), tensor(61.7978), tensor(52.8090), tensor(58.8889)]
average accuracy 58.368564491271975
average loss 1.6124976995126457
average train accuracy: 61.42953090667724
average accuracy ct 61.243399925231934
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336, 58.15799301147461, 58.35487148284912, 58.368564491271975]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131, 61.38775100708008, 61.35578327178955, 61.42953090667724]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098, 61.07480003356934, 61.06450000762939, 61.243399925231934]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245, 60690165, 57040452, 57149685]
training iter: 51 of 400
In this round, 10 clients are trained---->>>>
[39, 15, 89, 94, 8, 6, 35, 90, 20, 18]
Before Training, their test accuracy:
[array(51.685394, dtype=float32), array(51.685394, dtype=float32), array(57.142857, dtype=float32), array(62.365593, dtype=float32), array(52.80899, dtype=float32), array(47.19101, dtype=float32), array(54.945053, dtype=float32), array(63.333332, dtype=float32), array(57.30337, dtype=float32), array(57.30337, dtype=float32)]
After Finetune, their test accuracy:
[tensor(51.6854), tensor(53.9326), tensor(57.1429), tensor(64.5161), tensor(52.8090), tensor(44.9438), tensor(56.0440), tensor(61.1111), tensor(51.6854), tensor(53.9326)]
After distillation, their test accuracy:
[tensor(52.8090), tensor(59.5506), tensor(60.4396), tensor(62.3656), tensor(46.0674), tensor(49.4382), tensor(50.5494), tensor(63.3333), tensor(59.5506), tensor(51.6854)]
average accuracy 58.368811416625974
average loss 1.6290003226247547
average train accuracy: 61.42717975616455
average accuracy ct 61.10739994049072
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336, 58.15799301147461, 58.35487148284912, 58.368564491271975, 58.368811416625974]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131, 61.38775100708008, 61.35578327178955, 61.42953090667724, 61.42717975616455]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098, 61.07480003356934, 61.06450000762939, 61.243399925231934, 61.10739994049072]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245, 60690165, 57040452, 57149685, 57167712]
training iter: 52 of 400
In this round, 10 clients are trained---->>>>
[75, 96, 86, 33, 24, 27, 31, 51, 6, 85]
Before Training, their test accuracy:
[array(59.782608, dtype=float32), array(64.044945, dtype=float32), array(55.172413, dtype=float32), array(50.5618, dtype=float32), array(61.797752, dtype=float32), array(64.83517, dtype=float32), array(53.932583, dtype=float32), array(57.77778, dtype=float32), array(49.4382, dtype=float32), array(57.30337, dtype=float32)]
After Finetune, their test accuracy:
[tensor(61.9565), tensor(59.5506), tensor(52.8736), tensor(55.0562), tensor(55.0562), tensor(58.2418), tensor(52.8090), tensor(55.5556), tensor(55.0562), tensor(58.4270)]
After distillation, their test accuracy:
[tensor(63.0435), tensor(65.1685), tensor(49.4253), tensor(59.5506), tensor(55.0562), tensor(73.6264), tensor(57.3034), tensor(61.1111), tensor(51.6854), tensor(57.3034)]
average accuracy 58.55508193969727
average loss 1.6320871393065501
average train accuracy: 61.44248180389404
average accuracy ct 61.16449996948242
average accuracy list [54.27223934173584, 54.26184425354004, 54.503770637512204, 54.88506675720215, 55.32259052276611, 55.365720672607424, 54.63144199371338, 55.04196773529053, 55.28510669708252, 54.94083549499512, 55.14181995391846, 55.57562297821045, 55.66448642730713, 55.69867946624756, 55.39026294708252, 55.67296371459961, 55.90153781890869, 55.7521280670166, 55.558908462524414, 55.54628215789795, 55.576596641540526, 55.96779186248779, 55.99076068878174, 56.09327018737793, 56.118490028381345, 56.295631103515625, 56.36298610687256, 56.82244873046875, 56.90454341888428, 56.69501411437988, 56.67693172454834, 56.85348846435547, 57.01099807739258, 57.30393257141113, 57.424517517089846, 57.39209930419922, 57.50577156066895, 57.60351013183594, 57.48957656860352, 57.59198310852051, 57.480126190185544, 57.82784496307373, 57.8609574508667, 57.6940302658081, 57.71813968658447, 57.802834358215335, 57.88098377227783, 57.98010971069336, 58.15799301147461, 58.35487148284912, 58.368564491271975, 58.368811416625974, 58.55508193969727]
averge_train_accuracy_list [56.127067718505856, 56.26826232910156, 56.20110355377197, 56.607848777771, 57.034880790710446, 57.09573257446289, 56.67109725952148, 56.90446979522705, 57.10094303131103, 56.95323001861572, 57.002083969116214, 57.44645793914795, 57.826720809936525, 57.92054088592529, 57.989750442504885, 58.009285888671876, 58.39811553955078, 58.331346321105954, 58.26177474975586, 58.351566772460934, 58.39158657073975, 58.25086181640625, 58.49691860198975, 58.80938617706299, 59.04664794921875, 59.17736782073975, 59.35148426055908, 59.38482791900635, 59.49888442993164, 59.57138126373291, 59.56334812164307, 59.74935424804688, 59.81599075317383, 60.08997211456299, 60.23667839050293, 60.3529623413086, 60.519708137512204, 60.666029090881345, 60.79144439697266, 60.802087020874026, 60.836422996520994, 60.914876289367676, 60.96305648803711, 61.042947921752926, 61.09198516845703, 61.177403602600094, 61.2523751449585, 61.27715358734131, 61.38775100708008, 61.35578327178955, 61.42953090667724, 61.42717975616455, 61.44248180389404]
averge_ct_accuracy_list [56.46749862670899, 56.481598777771, 56.562298965454104, 56.905699005126955, 57.33059909820557, 57.39509925842285, 56.849299392700196, 57.07509952545166, 57.320799560546874, 57.11259960174561, 57.168699684143064, 57.57279975891113, 57.85649978637695, 57.91679985046387, 57.831599922180175, 58.008600006103514, 58.23980003356934, 58.067500076293946, 58.117800064086914, 58.1042000579834, 58.154799995422366, 58.17540004730225, 58.37860000610352, 58.6346000289917, 58.817100067138675, 58.971500091552734, 59.085000076293944, 59.171799964904785, 59.32879997253418, 59.42269992828369, 59.43399982452392, 59.617499885559084, 59.57079978942871, 59.76589981079101, 59.940499801635745, 60.01089984893799, 60.13259994506836, 60.23719989776611, 60.297499923706056, 60.37009990692139, 60.37549991607666, 60.48539993286133, 60.52409999847412, 60.73579998016358, 60.86770004272461, 60.969000091552736, 60.993200073242186, 60.95470008850098, 61.07480003356934, 61.06450000762939, 61.243399925231934, 61.10739994049072, 61.16449996948242]
total_num_list [200350180, 139392454, 134740471, 129981491, 124946902, 120273771, 124874587, 134604915, 103878967, 92273313, 103947601, 121619011, 110701402, 93979952, 82783546, 95593149, 83924081, 87110087, 74618085, 79127630, 87421433, 77123057, 75685054, 60744885, 63952221, 68717899, 79188193, 60893754, 64211502, 69021379, 60632358, 67207788, 72231323, 57295080, 68917366, 57261328, 57066525, 60756180, 60567720, 60444105, 60486405, 60765108, 60635328, 56947761, 56954565, 57028977, 57168954, 57225042, 57127833, 56959245, 60690165, 57040452, 57149685, 57167712, 57208338]
